---
title: Supplementary Material (A) - Testing the Circumplex Structure of the Soundscape Survey
description: |
  Accompanying the paper: "Soundscape descriptors in eighteen languages: translation and validation through listening experiments
author:
  - name: Andrew Mitchell
    email: andrew.mitchell.18@ucl.ac.uk
    affiliations: 
        - id: ucl-iede
          name: University College London
          department: Institute for Environmental Design and Engineering
          address: Central House, 14 Upper Woburn Place
          city: London
          state: UK
          postal-code: WC1H 0NN
    attributes:
        corresponding: true
    orcid: 0000-0003-0978-5046
  - name: Francesco Aletta
    email: f.aletta@ucl.ac.uk
    orcid: 0000-0003-0351-3189
    affiliations:
        - ref: ucl-iede
abstract: |

date: last-modified
---


```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = knitr::is_html_output())
is_html <- knitr::is_html_output()
```



## Introduction

In this analysis, we aim to test the circumplex structure of various soundscape survey translations. The circumplex model is a powerful tool in psychology, often used to visualize and interpret complex multivariate data. In order to enable its use across many contexts, cultures, and languages, its necessary to validate the structure of the circumplex items. The goal of validated translations is to ensure that the circumplex structure is maintained across translations, allowing for cross-cultural comparisons.

Our approach will involve several steps. First, we will load the necessary libraries and our dataset. The dataset comprises responses to the soundscape survey in various languages. Each response includes ratings on a set of scales (the perceptual attributes from @Axelsson2010principal (PAQs)), which we will use to analyze the circumplex structure.

Next, we will prepare the variables for the circumplex analysis. This includes defining the names of the scales used in the survey and the ideal angles for the circumplex analysis. These angles represent the theoretical ideal locations of each scale on the circumplex.

After loading and preparing the data, we will proceed to the analysis phase. We will use the CircE package, a tool specifically designed for circumplex analysis. This will allow us to test the circumplex structure of the survey translations and visualize the results.

### Testing the Circumplex

The concept of the psychometric circumplex model, first introduced by Guttman in 1954, revolves around the idea of a circular relationship among variables. This means that the correlations between these variables follow a pattern that increases and decreases in a way that resembles a cosine wave, as explained by Grassi, Luccio, & di Blas in 2010 and Yik & Russell in 2004.

Guttman made a distinction between two types of models: the quasi-circumplex model and the circulant model. The quasi-circumplex model represents a loosely ordered circular arrangement of variables without any specific constraints on the distances between them. On the other hand, the circulant model, as proposed by Guttman, enforces an equal spacing constraint, meaning that the distances between the variables in the circular arrangement are kept equal. *[cite this]*

::: {.callout-note}
Rephrase this paragraph to better match Browne.
:::

Browne further expanded on the circumplex model in 1992 and 1995 by differentiating between equal spacing and equal communality (or radii) constraints. Browne described four variations of circumplex models, which include three types of quasi-circumplex models and one circulant model. These variations include the unconstrained or loosely ordered quasi-circumplex, the equal spacing quasi-circumplex, the equal communality quasi-circumplex, and the circulant model that maintains both equal spacing and equal communality.

## Data Preparation

```{r load data, warning=FALSE}
#| output: false

library(devtools)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(readxl)
library(here)
library(knitr)
library(CircE)
library(RCurl)

source(here("utils/sem_funcs.R")) # Load our own functions
dir.create(here("outputs", Sys.Date()), showWarnings = FALSE) # Create a folder for the outputs
output_dir <- here("outputs", Sys.Date())

# Prep variables for the circumplex analysis
scales <- c("PAQ1", "PAQ2", "PAQ3", "PAQ4", "PAQ5", "PAQ6", "PAQ7", "PAQ8") # Names of the scales for circumplex analysis
eq.angles <- c(0, 45, 90, 135, 180, 225, 270, 315) # Ideal angles for circumplex analysis

# Load in the SATP dataset from Zenodo
temp.file <- paste0(tempfile(), ".xlsx")
download.file(
    "https://zenodo.org/records/10159673/files/SATP%20Dataset%20v1.4.xlsx",
    temp.file,
    mode="wb")
satp <- read_excel(temp.file,
    na = c("", "N/A"),
    col_types = c(
        "text", "text", "text", # Lan, Rec, Part
        "numeric", # Age
        "text", # Gender
        "numeric", "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", "numeric", # PAQs
        "numeric", # loud
        "text", # Inst
        "numeric" # sequence
    )
  )

```


### Ipsatization

Ipsatization is a process used in psychology to adjust for individual differences in response style when analyzing survey data. It involves transforming each participant's responses by subtracting their mean response across all items from their response to each individual item. This process can help to control for individual differences in the use of response scales, such as some participants being more likely to use extreme responses than others.

In the context of this code, ipsatization is being used to adjust the responses to the soundscape survey. The goal is to ensure that the analysis of the circumplex structure of the survey translations is not unduly influenced by individual differences in response style. By subtracting the mean of each participant's responses across all scales from their response to each scale, the analysis can focus more on the relative differences between the scales for each participant, rather than the absolute values of the responses.


```{r}
# Ipsatize the data
# For each participant, we subtract the mean of their response to all scales
# across all recordings from their response to each scale for each recording
# This is done at the suggestion of JM Girard/R Circumplex

satp |>
    group_by(Participant) |>
    mutate(Mean = mean(c_across(scales), na.rm = TRUE)) -> parts_means

satp[scales] <- satp |>
    select(all_of(scales)) |>
    mutate(across(all_of(scales), ~ .x - parts_means$Mean))
```


### Acoustic Data

In addition to the survey responses, we also have acoustic data for each recording. This data includes the $L_{eq}$, $L_{Aeq}$, N, and $L_{A90}$ values for each recording. These values are used to calculate the acoustic indices for each recording, which can then be correlated with the survey responses. This will be used later, in the validation of the survey instrument.

```{r}
# Load the acoustic analysis data
lvls <- read_excel(here("data/LLAN.xlsx"),
    skip = 1,
    na = c("", "N/A"),
    col_types = c("text", "text", "numeric", "numeric", "numeric", "numeric"),
    col_names = c("Recording", "Channel", "Leq", "LAeq", "N", "LA90")
)


# Extract the max for each recording to reduce from two channels to one
result <- lvls |>
    group_by(Recording) |>
    mutate(max_N = ifelse(row_number() == 1, max(N), NA_integer_)) |>
    select(Recording, max_N) |>
    na.omit()

# Join to SATP dataset
satp <- left_join(satp, result, by = join_by(Recording == Recording))
```



## Structural Equation Modelling using Browne's Stochastic Circumplex Model

In the context of the soundscape survey translations, we use CircE to test the circumplex structure of the survey responses. This involves running four different models for each language and compiling the results into a single table.

The models are assessed against a suite of SEM fit indices, which are statistical measures used to evaluate the goodness of fit of the models. These indices include the Chi-squared test, Comparative Fit Index (CFI), Goodness of Fit Index (GFI), Standardized Root Mean Square Residual (SRMR), and Root Mean Squared Error of Approximation (RMSEA).

### Fit Indices

| **Fit Index**                                     | **Threshold** |
| :------------------------------------------------ | :-----------: |
| Chi-squared ($\chi^2$)                            | *p < 0.05*    |
| Comparative Fit Index (CFI)                       | *0.90*        |
| Goodness of Fit Index (GFI)                       | *0.90*        |
| Standardized Root Mean Square Residual  (SRMR)    | *0.08*        |
| Root Mean Squared Error of  Approximation (RMSEA) | *0.13*        |
| Minimum Common Score Correlations  (MCSC)         | *-0.8*        |
| Gap difference test (GDIFF)                       | *20*          |

: Fit indices and thresholds, including the reference from which the threshold is derived. {#tbl-indices}


Each model is assessed against a suite of SEM fit indices, summarised in @tbl-indices. These indices include the $\chi^2$ test, Comparative Fit Index (CFI), Goodness of Fit Index (GFI), Standardized Root Mean Square Residual (SRMR), and Root Mean Squared Error of Approximation (RMSEA). Two additional indices are calculated which are not considered 'typical' fit indices for SEMs, but which have proved to be crucial for the analysis of the circumplex. 

Interpreting the results of the SEM circumplex analysis using CircE involves understanding the various fit indices and their implications.

1. Chi-squared test ($\chi^2$): This is a statistical test to determine if the observed data matches the expected data. A low $\chi^2$ value indicates a good fit.

2. Comparative Fit Index (CFI): This index compares the model of interest to a baseline model. Values close to 1 indicate a good fit.

3. Goodness of Fit Index (GFI): This index measures the proportion of variance that is accounted for by the estimated population covariance. Values close to 1 indicate a good fit.

4. Standardized Root Mean Square Residual (SRMR): This is the square root of the discrepancy between the residuals of the sample covariance matrix and the hypothesized covariance model. Values less than 0.08 are generally considered good.

<!-- 5. Root Mean Squared Error of Approximation (RMSEA): This index measures the lack of fit per degree of freedom in the model. Values less than 0.06 are generally considered good. -->

6. Minimum Common Score Correlations (MCSC): This index measures the minimum correlation between any two variables in the model. Higher values indicate a better fit.

<!-- 7. Gap Difference test (GDIFF): This test quantifies the proximity of the estimated angles to the ideal circumplex. It calculates all squared differences between ideal and observed angles. Smaller values indicate greater circumplexity of the scores. -->

7. Procrustes Rotation Congruence (PRC): This index measures the congruence between the ideal and observed angles. Values close to 1 indicate a good fit.

#### Inter-rater Reliability

Note that we do not report a measure of Inter-rater Reliability (IRR) for the original survey data as a test of the validity of the survey instrument. Although this has been used previously in soundscape research [see @Erfanian2021Psychological and @Tarlao2020Investigating], we feel that IRR imposes assumptions which do not necessarily hold in soundscape research. Primarily, IRR tests make the assumption that for a reliable response, raters should have high agreement about the subject. To rely on an IRR for a soundscape survey instrument would impose an external requirement that all listeners agree on the emotional affect evoked by a particular sound. In the context of the SATP dataset, where all participants were exposed to the same recording, an IRR metric such as Kendall's coefficient of concordance $W$, could be applied for the ratings given for each recording, with a high $W$ theoretically indicating good instrument reliability. However, what it would actually indicate is a high degree of agreement regarding the emotional affect of that recording. As noted in @Mitchell2022How, this assumption should not necessarily be applied to soundscape assessments, given that respondents would be expected to have differing perceptual responses to the same sound and, in fact, this variability in response should be one of the outcomes to be investigated by researchers. A low IRR would therefore not necessarily indicate a poor measurement instrument, but instead could indicate a sound for which there is valid disagreement about the perception. A sound which for some groups is considered pleasant and for others it is annoying would result in a low IRR, completely independent of the validity of the measurement instrument.

Instead, the goal of the validity testing presented here is to confirm whether the soundscape survey instrument

### Run `CircE` Analysis

The bulk of the code for this process has been pulled out into a separate `sem_funcs.R` file, which is loaded at the beginning of the analysis. This file contains the functions used to run the circumplex analysis and compile the results into a single table.

`step_one_test(data, model_type, scales = c("PAQ1", "PAQ2", "PAQ3", "PAQ4", "PAQ5", "PAQ6", "PAQ7", "PAQ8"), m = 3) )` is the function used to run the circumplex analysis for a single model for a single language. It takes the data for that language, the model_type (one of `Circumplex`, `Equal comm.`, `Equal ang.`, or `Unconstrained`), the names of the scales, and the number of betas for the fourier series correlation function (we're using `m=3` by default). It then runs the analysis and returns a list of the results, including a list of the desired results (`res_list`) and the model object (`res_model`). 

`run_all_models(data, datasource, language, m)` is the function used to run the circumplex analysis for all four models for a single language. It takes the data for that language, the name of the data source (e.g. `SATP`), the language code, and the number of betas for the fourier series correlation function (m). It then runs the analysis for each of the four models and returns a list of the results, including a list of the four results and a table combining the results from all four models. 

First, we run the circumplex analysis for the English data. This is done separately from the other languages to set up the results data table.


```{r}
#| output: false

# Run the models for English
satp_eng <- satp[satp$Language == "eng", ]
circe_satp_eng <- run_all_models(satp_eng, "SATP", "eng", m = 3)

```

Then, we run the circumplex analysis for each of the other languages. This is done in a loop, with each language being run separately. The results for each language are then added to the results table.

Within each loop, we check for any errors in execution and append these to a list of errors to inspect later.

```{r}
#| output: false

languages <- unique(satp$Language) # Get a list of all the languages

full_table <- circe_satp_eng$res_table # Start with the English results
for (lang in languages) {
    if (lang == "eng") {
        next # Skip English, we've already done it
    }
    print("=====================================")
    print(lang)
    print("=====================================")
    lang_data <- satp[satp$Language == lang, ] # Filter to just the language we want
    
    pass_on_error <- FALSE
    errors <- list()
    tryCatch(
      lang_res <- run_all_models(lang_data, "SATP", lang, m = 3), 
      error = function(e) {
        pass_on_error <<- TRUE
        errors[lang] <<- e
      }
    )
    if (pass_on_error) {
      next
    }
    # lang_res <- run_all_models(lang_data, "SATP", lang, m = 3) # Run the models
    full_table <- rbind(full_table, lang_res$res_table) # Add the results to the table
}

```

`zsm` fails to converge, even under different constraints and choice of `m` betas. We will therefore exclude it from the analysis moving forward and label is as 'Model failed to converge'.

```{r}
for (name in names(errors)) {
  print("==========  Error in:  =============")
  print(errors[name])
}
```

### SEM Analysis Results

Below is the table of results for the circumplex analysis of the soundscape survey translations. The table includes the results for each of the four models for each language. The results are presented in the order of the models, with the unconstrained model first, followed by the equal spacing model, the equal communality model, and the circumplex model. The results for each model include the $\chi^2$ test, CFI, GFI, SRMR, RMSEA, MCSC, and GDIFF. These results are saved to a CSV file for later use.

Importantly, this table also reports the derived angles for each scale for the unconstrained and Equal comm. models. These angles will be carried over and used in the next stage of the analysis, where we will validate the survey instrument by correlating the survey responses with the acoustic indices using the Structural Summary Method (SSM).

```{r, results='asis'}
write.csv(full_table, here(output_dir, "sem-fit-ipsatized.csv"))
if (is_html) {
    kable(full_table, digits = 3, align = "c") %>%
        kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", "bordered"))
} else {
    kableExtra::kbl(
      full_table[, ! colnames(full_table) %in% c('Dataset', 'Model Type', 'RMSEA.L', 'RMSEA.U', 'GDIFF', scales)],
      format = "latex",
      row.names = FALSE,
      booktabs = T,
      digits = 3,
      align = "c",
      longtable = TRUE,
      linesep = c("", "", "", "\\addlinespace")
    ) |>
    kableExtra::kable_classic_2()
}
```

